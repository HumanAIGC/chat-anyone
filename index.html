<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="ChatAnyone">
    <meta property="og:title" content="ChatAnyone"/>
    <meta property="og:description"
          content="ChatAnyone: Stylized Real-time Portrait Video Generation with Hierarchical Motion Diffusion Model."/>
    <meta property="og:url" content="URL OF THE WEBSITE"/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/video_t1.png"/>
    <meta property="og:image:width" content="2412"/>
    <meta property="og:image:height" content="1394"/>


    <meta name="twitter:title" content="EMO">
    <meta name="twitter:description"
          content="ChatAnyone: Stylized Real-time Portrait Video Generation with Hierarchical Motion Diffusion Model.">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/video_t1.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="Image-to-Video">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>ChatAnyone: Stylized Real-time Portrait Video Generation with Hierarchical Motion Diffusion Model</title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link href="https://fonts.googleapis.com/css2?family=Jost:wght@300;400;500&display=swap" rel="stylesheet">

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
</head>

<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
        </a>
    </div>
    <div class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
            <a class="navbar-item" href=https://github.com/HumanAIGC>
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
            </a>

            <div class="navbar-item has-dropdown is-hoverable">
                <a class="navbar-link">
                    More Research
                </a>
                <div class="navbar-dropdown">
                    <a class="navbar-item" href="https://humanaigc.github.io/emote-portrait-alive/">
                        EMO
                    </a>

                    <a class="navbar-item" href="https://humanaigc.github.io/animate-anyone/">
                        AnimateAnyone
                    </a>
                    <a class="navbar-item" href="https://humanaigc.github.io/outfit-anyone/">
                        OutfitAnyone
                    </a>
                    <a class="navbar-item" href="https://github.com/HumanAIGC/MaTe3D/">
                        MaTe3D
                    </a>
                    <a class="navbar-item" href="https://humanaigc.github.io/vivid-talk/">
                        VividTalk
                    </a>
                    <a class="navbar-item" href="https://tomguluson92.github.io/projects/cloth2tex/">
                        Cloth2Tex
                    </a>

                </div>
            </div>
        </div>

    </div>
</nav>

<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">ChatAnyone: Stylized Real-time Portrait Video Generation with Hierarchical Motion Diffusion Model</h1>
                    <div class="is-size-5 publication-authors">
                        <!-- Paper authors -->
                        <span class="author-block">
                <a href="https://dblp.org/pid/183/0937.html" target="_blank">Jinwei Qi</a>,</span>
                        <span class="author-block">
                <a href="https://dblp.org/pid/189/3461.html" target="_blank">Chaonan ji</a>,</span>
                        <span class="author-block">
                <a href="https://dblp.org/pid/10/1887-7.html" target="_blank">Sheng Xu</a>,</span>
                        <span class="author-block">
                <a href="https://scholar.google.com/citations?user=QTgxKmkAAAAJ" target="_blank">Peng Zhang</a>,</span>
                        <span class="author-block">
                <a href="https://dblp.org/pid/11/4046.html" target="_blank">Bang Zhang</a>,</span>
                        <span class="author-block">
                <a href="https://scholar.google.com/citations?user=FJwtMf0AAAAJ&hl=zh-CN" target="_blank">Liefeng Bo</a>
                        </span>
                    </div>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block">Tongyi Lab, Alibaba Group</span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <span class="link-block">
                  <a href="https://arxiv.org/abs/2503.21144" target="_blank"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<section class="hero is-small">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <!-- <h2 class="title is-3">Facial Motion Generation</h2> -->
            <div style="display: flex; justify-content: center; align-items: center;">
                <img src="content/overview.png" alt="MY ALT TEXT" style="width: 95%; height: 95%;"/>
            </div>
            <div class="item">
                <h2 class="content has-text-justified">
                    <p style="font-size: 1.2em;">
                        Illustration of real-time portrait video generation. Given a portrait image and audio sequence as input, our model can generate high-fidelity animation results from full head to upper-body interaction with diverse facial expressions and style control.
                    </p>
                </h2>
                <div class="item">
                </div>
            </div>
</section>



<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <!--                <div style="display: flex; justify-content: center; align-items: center;">-->
                <!--                    <img src="content/images/framework/intro.png" alt="MY ALT TEXT" style="width: 80%; height: 80%;"/>-->
                <!--                </div>-->
                <div class="content has-text-justified">
                    <p style="font-size: 1.2em;">
                        Real-time interactive video-chat portraits have been increasingly recognized as the future trend, particularly due to the remarkable progress made in text and voice chat technologies. 
However, existing methods primarily focus on real-time generation of head movements, but struggle to produce synchronized body motions that match these head actions. Additionally, achieving fine-grained control over the speaking style and nuances of facial expressions remains a challenge. 
To address these limitations, we introduce a novel framework for stylized real-time portrait video generation, enabling expressive and flexible video chat that extends from talking head to upper-body interaction. Our approach consists of the following two stages. 
The first stage involves efficient hierarchical motion diffusion models, that take both explicit and implicit motion representations into account based on audio inputs, which can generate a diverse range of facial expressions with stylistic control and synchronization between head and body movements. 
The second stage aims to generate portrait video featuring upper-body movements, including hand gestures. We inject explicit hand control signals into the generator to produce more detailed hand movements, and further perform face refinement to enhance the overall realism and expressiveness of the portrait video. 
Additionally, our approach supports efficient and continuous generation of upper-body portrait video in maximum 512 × 768 resolution at up to 30fps on 4090 GPU, supporting interactive video-chat in real-time.
Experimental results demonstrate the capability of our approach to produce portrait videos with rich expressiveness and natural upper-body movements.
                    </p>
                </div>
            </div>
        </div>
        <!--                                            <video class="video-player" poster="" id="tree1" controls>-->
        <!--                    <source src="content/video/main_page.mp4" type="video/mp4">-->
        <!--                </video>-->
    </div>
</section>

<!-- Method -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <h2 class="title is-2">Method</h2>
            <div style="display: flex; justify-content: center; align-items: center;">
                <img src="content/inference_pipeline.png" alt="MY ALT TEXT" style="width: 95%; height: 95%;"/>
            </div>
            <div class="item">
                <h2 class="content has-text-justified">
                    <p style="font-size: 1.2em;">
                        <ul>
                            <li><strong>Efficient Hierarchical motion diffusion model</strong> is proposed for <u><i>audio2motion representation</i></u> to generate face and body control signals hierarchically based on input audio, considering both explicit and implicit motion signals for precise facial expressions. Furthermore, fine-grained expression control is introduced to realize different variations in expression intensity, as well as stylistic expression transfer from reference videos, which aims to produce controllable and personalized expressions.</li>
                            <li><strong>Hybrid control fusion generative model</strong> is designed for <u><i>upper-body image generation</i></u>, which utilizes explicit landmarks for direct and editable facial expression generation, while implicit offsets based on explicit signals are introduced to capture facial variations on diverse avatar styles. We also inject explicit hand controls for more accurate and realistic hand textures and movements. Additionally, a <i><u>face refinement</i></u> module is employed to enhance facial realism ensuring highly expressive and lifelike portrait videos.</li>
                            <li><strong>Extensible and real-time generation framework</strong> is constructed for interactive video chat application, which can adapt to various scenarios through flexible sub-module combinations, supporting tasks ranging from head-driven animation to upper-body generation with hand gestures. Besides, we establish an efficient streaming inference pipeline that achieves 30fps at a resolution of maximum 512 × 768 on 4090 GPU, ensuring smooth and immersive experiences in real-time video chat.</li>
                        </ul>
                    </p>
                </h2>
                <div class="item">
                </div>
            </div>
</section>

<!-- End Method -->

<style>
    .gifImage:hover {
        opacity: 0.8;
        box-shadow: 0 0 5px rgba(0, 0, 0, 0.5);
        transform: scale(1.1);
    }

    .paused {
        animation-play-state: paused;
    }

</style>


<head>
    <title>place gif</title>
    <style>
        .gif-container {
            display: flex;
        }

        .gif {
            width: 660px; /* 设置 GIF 的宽度 */
            height: 400px; /* 设置 GIF 的高度 */
        }
    </style>
</head>

<section class="hero is-small is-light">
    <div class="hero-body">
        <div class="container">
            <h2 class="title is-2">Results</h2>
            <br></br>
            <h2 class="content has-text-justified">
                <p style="font-size: 1.4em;"></p>
            </h2>

            <div style="display: flex; justify-content: center;align-items: center; height: 80px;">
                <h3 class="title is-4"> Audio-driven Upper-body Animation </h3>
            </div>
            <div class="content has-text-justified" style="display: flex; justify-content: center;align-items: center;">
                <p style="font-size: 1.2em;">
                    We can generate highly expressive audio-driven upper-body digital human videos, supporting different scenarios with or without hands.
                </p>
            </div>

            <style>
                .video-container {
                    display: flex;
                    justify-content: space-between; /* 使视频之间有间距 */
                    align-items: center;
                    margin-bottom: 20px; /* 视频下方的间距 */
                }
            
                .video-item {
                    flex: 1; /* 使每个视频项占据相等的空间 */
                    margin: 0 10px; /* 视频之间的间距 */
                }
            
                .video-player {
                    width: 100%; /* 确保视频宽度适应容器 */
                    max-width: 250px; /* 设置最大宽度以避免过大 */
                }
            </style>

            <div class="video-container">
                <div class="video-item">
                    <div class="column">
                        <video class="video-player" poster="" id="tree2" controls>
                            <source src="content/upper_body_woHand_1.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
                <div class="video-item">
                    <div class="column">
                        <video class="video-player" poster="" id="tree3" controls>
                            <source src="content/upper_body_woHand_2.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
                <div class="video-item">
                    <div class="column">
                        <video class="video-player" poster="" id="tree4" controls>
                            <source src="content/upper_body_wHand_4.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
                <div class="video-item">
                    <div class="column">
                        <video class="video-player" poster="" id="tree5" controls>
                            <source src="content/upper_body_wHand_3.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>

            <div style="display: flex; justify-content: center;align-items: center; height: 80px;">
                <h3 class="title is-4"> Audio-driven Talking Head Animation </h3>
            </div>
            <div class="content has-text-justified" style="display: flex; justify-content: center;align-items: center;">
                <p style="font-size: 1.2em;">
                    We can achieve highly accurate lip-sync results, as well as generate expressive facial expressions and natural head poses.
                </p>
            </div>

            <div class="video-container">
                <div class="video-item">
                    <div class="column">
                        <video class="video-player" poster="" id="tree2" controls>
                            <source src="content/talking_head_01.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
                <div class="video-item">
                    <div class="column">
                        <video class="video-player" poster="" id="tree3" controls>
                            <source src="content/talking_head_02.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
                <div class="video-item">
                    <div class="column">
                        <video class="video-player" poster="" id="tree4" controls>
                            <source src="content/talking_head_03.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
                <div class="video-item">
                    <div class="column">
                        <video class="video-player" poster="" id="tree5" controls>
                            <source src="content/talking_head_04.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>

            <div style="display: flex; justify-content: center;align-items: center; height: 80px;">
                <h3 class="title is-4"> Audio-driven Stylized Animation </h3>
            </div>
            <div class="content has-text-justified" style="display: flex; justify-content: center;align-items: center;">
                <p style="font-size: 1.2em;" >
                    We can generate audio-driven results for stylized characters, while also supporting the creation of highly expressive singing videos.
                </p>
            </div>

            <div class="video-container">
                <div class="video-item">
                    <div class="column">
                        <video class="video-player" poster="" id="tree2" controls>
                            <source src="content/talking_head_ani.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
                <div class="video-item">
                    <div class="column">
                        <video class="video-player" poster="" id="tree3" controls>
                            <source src="content/talking_head_ani_song.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
                <div class="video-item">
                    <div class="column">
                        <video class="video-player" poster="" id="tree4" controls>
                            <source src="content/upper_body_song_01.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
                <div class="video-item">
                    <div class="column">
                        <video class="video-player" poster="" id="tree5" controls>
                            <source src="content/upper_body_song_02.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>

            
            <div style="display: flex; justify-content: center;align-items: center; height: 80px;">
                <h3 class="title is-4"> Dual-host AI Podcasts Demo</h3>
            </div>
            <div class="content has-text-justified" style="display: flex; justify-content: center;align-items: center;">
                <p style="font-size: 1.2em;">
                    We can also generate dual-host podcasts, enabling AI-driven conversations.
                </p>
            </div>

            <style>
            
                .double-video-player {
                    width: 100%; /* 确保视频宽度适应容器 */
                    max-width: 600px; /* 设置最大宽度以避免过大 */
                }
            </style>

            <div class="video-container">
                <div class="video-item">
                    <div class="column">
                        <video class="double-video-player" poster="" id="tree2" controls>
                            <source src="content/talking_head_conversation_01_new.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
                <div class="video-item">
                    <div class="column">
                        <video class="double-video-player" poster="" id="tree3" controls>
                            <source src="content/talking_head_conversation_02_new.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>

            <div class="video-container">
                <div class="video-item">
                    <div class="column">
                        <video class="double-video-player" poster="" id="tree2" controls>
                            <source src="content/upper_body_conversation_01.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
                <div class="video-item">
                    <div class="column">
                        <video class="double-video-player" poster="" id="tree3" controls>
                            <source src="content/upper_body_conversation_02_new.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>

            <div style="display: flex; justify-content: center;align-items: center; height: 80px;">
                <h3 class="title is-4"> Interactive Demo </h3>
            </div>
            <div class="content has-text-justified" style="display: flex; justify-content: center;align-items: center;">
                <p style="font-size: 1.2em;">
                    Our approach achieves real-time generation of 30fps on a 4090 GPU, supporting practical application for interactive video chat.
                </p>
            </div>

            <style>
                .single-video-container {
                    display: flex;
                    justify-content: center; /* 使视频居中 */
                    align-items: center;
                    margin-bottom: 20px; /* 视频下方的间距 */
                }
            
                .single-video-item {
                    width: 50%; /* 使视频项占据整个容器的宽度 */
                }
            
                .single-video-player {
                    width: 100%; /* 确保视频宽度适应容器 */
                    max-width: 1000px; /* 设置最大宽度为1000px */
                }
            </style>


            <div class="single-video-container">
                <div class="single-video-item">
                    <video class="single-video-player" poster="" id="tree2" controls>
                        <source src="content/upper_body_interactive_demo.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
<!-- 
            <div style="display: flex; justify-content: center;align-items: center; height: 80px;">
                <h3 class="title is-4"> Expression & Pose Decoupled Control </h3>
            </div>
            <div class="content has-text-justified" style="display: flex; justify-content: center;align-items: center;">
                <p style="font-size: 1.2em;">
                    We can generate a wide range of driven results, combining varying intensities of decoupled facial movements and head motions.
                </p>
            </div>

            <style>
                .single-video-container {
                    display: flex;
                    justify-content: center; /* 使视频居中 */
                    align-items: center;
                    margin-bottom: 20px; /* 视频下方的间距 */
                }
            
                .single-video-item {
                    width: 50%; /* 使视频项占据整个容器的宽度 */
                }
            
                .single-video-player {
                    width: 100%; /* 确保视频宽度适应容器 */
                    max-width: 1000px; /* 设置最大宽度为1000px */
                }
            </style>

            <div class="single-video-container">
                <div class="single-video-item">
                    <video class="single-video-player" poster="" id="tree2" controls>
                        <source src="content/expression_pose_decouple_demo.mp4" type="video/mp4">
                    </video>
                </div>
            </div>

            <div style="display: flex; justify-content: center;align-items: center; height: 80px;">
                <h3 class="title is-4"> Expression Style Transfer from Ref Video </h3>
            </div>
            <div class="content has-text-justified" style="display: flex; justify-content: center;align-items: center;">
                <p style="font-size: 1.2em;">
                    We can effectively transfer the reference style to final output, enabling high-freedom and controllable facial expression generation.
                </p>
            </div>


            <div class="single-video-container">
                <div class="single-video-item">
                    <video class="single-video-player" poster="" id="tree2" controls>
                        <source src="content/expression_transfer_v2.mp4" type="video/mp4">
                    </video>
                </div>
            </div> -->

            <br></br>
        </div>
    </div>
</section>


<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content" style="text-align: center;">
                    <p>
                        This project is intended for research purposes only. We strongly encourage users to use this project and its
                        generated video responsibly. We are not responsible for any misuse or abuse of this project. By using this project,
                        you agree to comply with all applicable laws and ethical guidelines.
                    </p>

                    <p>
                        This page was built using the <a
                            href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                            target="_blank">Template</a> which was adopted from the <a href="https://nerfies.github.io"
                                                                                       target="_blank">Nerfies</a> project
                        page.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

<script src="static/js/script.js"></script>
<script>
    // 获取所有视频元素
    var videos = document.querySelectorAll('video');

    // 为每个视频添加播放事件监听器
    videos.forEach(function (video) {
        video.addEventListener('play', function () {
            // 当任何一个视频开始播放时，暂停其他所有视频
            videos.forEach(function (otherVideo) {
                if (otherVideo !== video) {
                    otherVideo.pause();
                }
            });
        }, false);
    });
</script>

<script>
    new BeforeAfter({
        id: '#example1'
    });
    new BeforeAfter({
        id: '#example2'
    });
    new BeforeAfter({
        id: '#example3'
    });
    new BeforeAfter({
        id: '#example4'
    });
    new BeforeAfter({
        id: '#example6'
    });
    new BeforeAfter({
        id: '#example7'
    });

</script>

<script>
    var gifImage = document.getElementById('gifImage');
    var isPaused = false;

    gifImage.addEventListener('mouseenter', function () {
        gifImage.src = gifImage.src;
        isPaused = true;
    });

    gifImage.addEventListener('mouseleave', function () {
        if (isPaused) {
            gifImage.src = gifImage.src;
            isPaused = false;
        }
    });
</script>

<script>
    bulmaCarousel.attach('#results-carousel11', {
        slidesToScroll: 1,
        slidesToShow: 2,
        infinite: true,
        autoplay: false,
    });
    bulmaCarousel.attach('#results-carousel22', {
        slidesToScroll: 1,
        slidesToShow: 1,
        infinite: true,
        autoplay: false,
    });
    bulmaCarousel.attach('#results-carousel44', {
        slidesToScroll: 1,
        slidesToShow: 2,
        infinite: false,
        autoplay: false,
    });
</script>

<script>
    document.getElementById('gifImage3').src = 'content/gifs/Item.gif';
    document.getElementById('gifImage1').src = 'content/gifs/s1.gif';
    document.getElementById('gifImage2').src = 'content/gifs/s2.gif';

    // 图片资源路径
    const images = [
        'content/teaser/t3.gif',
        'content/teaser/t4.gif',
        'content/teaser/t1.gif',
        'content/teaser/t2.gif'
    ];

    // 获取要插入图片的div
    const group1 = document.getElementById('group1');
    const group2 = document.getElementById('group2');

    // 创建并插入前两张图片
    for (let i = 0; i < 2; i++) {
        const img = document.createElement('img');
        img.src = images[i];
        img.loading = 'lazy';
        img.alt = '图片' + (i + 1);
        group1.appendChild(img);
    }

    // 创建并插入后两张图片
    for (let i = 2; i < images.length; i++) {
        const img = document.createElement('img');
        img.src = images[i];
        img.loading = 'lazy';
        img.alt = '图片' + (i + 1);
        group2.appendChild(img);
    }

</script>
<!-- Default Statcounter code for shuziren
https://humanaigc.github.io/chat-anyone/ -->
<script type="text/javascript">
    var sc_project=13109483; 
    var sc_invisible=1; 
    var sc_security="8eb46992"; 
    </script>
    <script type="text/javascript"
    src="https://www.statcounter.com/counter/counter.js"
    async></script>
    <noscript><div class="statcounter"><a title="Web Analytics"
    href="https://statcounter.com/" target="_blank"><img
    class="statcounter"
    src="https://c.statcounter.com/13109483/0/8eb46992/1/"
    alt="Web Analytics"
    referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
    <!-- End of Statcounter Code -->
</body>


</html>
